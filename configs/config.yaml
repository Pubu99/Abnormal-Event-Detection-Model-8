d# Main Configuration File for Anomaly Detection System
# All paths, hyperparameters, and settings

# Project Settings
project:
  name: "Multi-Camera-Anomaly-Detection"
  version: "1.0.0"
  description: "Real-time anomaly detection for surveillance systems"
  seed: 42

# Data Configuration
data:
  root_dir: "data/raw"
  train_dir: "data/raw/Train"
  test_dir: "data/raw/Test"
  processed_dir: "data/processed"

  # Dataset properties
  image_size: [64, 64]
  num_classes: 14
  classes:
    - "Abuse"
    - "Arrest"
    - "Arson"
    - "Assault"
    - "Burglary"
    - "Explosion"
    - "Fighting"
    - "NormalVideos"
    - "RoadAccidents"
    - "Robbery"
    - "Shooting"
    - "Shoplifting"
    - "Stealing"
    - "Vandalism"

  # Normal class (everything else is anomaly)
  normal_class_idx: 7 # NormalVideos

  # Data loading
  num_workers: 8
  pin_memory: true
  prefetch_factor: 2

# Model Configuration
model:
  name: "HybridAnomalyDetector"

  # Backbone
  backbone:
    type: "efficientnet_b0" # Fast and accurate
    pretrained: true
    freeze_backbone: false
    dropout: 0.5  # INCREASED: Stronger regularization to prevent overfitting

  # Temporal modeling
  temporal:
    type: "lstm" # Options: lstm, gru, transformer
    hidden_dim: 256
    num_layers: 2
    bidirectional: true
    dropout: 0.5  # INCREASED: Stronger regularization to prevent overfitting

  # Feature dimensions
  feature_dim: 512
  embedding_dim: 128

    # Anomaly detection head (Deep SVDD)
  anomaly_head:
    type: "deep_svdd" # Deep Support Vector Data Description
    center_learning: true
    nu: 0.1 # Outlier fraction
    loss_weight: 0.05  # EMERGENCY FIX: Much lower to prevent gradient explosion (was 0.3)
    warmup_epochs: 5  # Don't use SVDD loss for first 5 epochs

# Training Configuration
training:
  # Basic settings
  epochs: 100
  batch_size: 128 # Optimized for RTX 5090
  gradient_accumulation_steps: 1 # Accumulate gradients over N steps (simulate larger batch)

  # Learning rate - Ultra-conservative for NaN prevention (PROVEN STABLE)
  learning_rate: 0.0001  # DO NOT INCREASE - this works!
  max_learning_rate: 0.001  # DO NOT INCREASE - this works!

  lr_scheduler:
    type: "onecycle" # Options: onecycle, cosine_annealing, reduce_on_plateau
    # OneCycleLR - ADJUSTED for better generalization
    T_max: 100
    eta_min: 0.00001
    warmup_epochs: 10  # INCREASED from 5 - gentler warmup
    pct_start: 0.2  # REDUCED from 0.3 - peak LR earlier to avoid late instability
    div_factor: 25 # Initial LR = max_lr / div_factor
    final_div_factor: 10000 # Final LR = max_lr / final_div_factor

  # Optimizer
  optimizer:
    type: "adamw"
    weight_decay: 0.01  # INCREASED from 0.0001 - stronger L2 regularization (100x stronger)
    betas: [0.9, 0.999]
  
  # Gradient clipping - EMERGENCY FIX for NaN prevention
  gradient_clip:
    enabled: true
    max_norm: 1.0  # Clip gradients to prevent explosion
    norm_type: 2  # L2 norm

  # Sharpness-Aware Minimization (SAM) - KEEP DISABLED until epoch 10
  # Seeks flat minima for better generalization on unseen data
  sam:
    enabled: false  # DISABLED: Will enable manually after verifying stability
    rho: 0.02  # REDUCED from 0.05 - even smaller perturbation for safety
    adaptive: false # Use ASAM (adaptive SAM)

  # Stochastic Weight Averaging (SWA) - NEW!
  # Averages weights over training for better generalization
  swa:
    enabled: true
    start_epoch: 75 # Start SWA at 75% of training
    lr: 0.00005 # SWA learning rate
    anneal_epochs: 10

  # Advanced Augmentation - TEMPORARILY DISABLED FOR STABILITY
  # Mixup and CutMix for better generalization (milder to reduce confusion)
  mixup_cutmix:
    enabled: false  # DISABLED: May cause numerical instability
    mixup_alpha: 0.1  # REDUCED from 0.2 - gentler mixing
    cutmix_alpha: 0.5  # REDUCED from 1.0 - gentler cutting
    prob: 0.3  # REDUCED from 0.5 - apply less frequently
    switch_prob: 0.5 # Probability of mixup vs cutmix

  # Loss function - ENHANCED for class imbalance
  loss:
    type: "focal" # Better for class imbalance
    alpha: 0.25
    gamma: 2.5  # INCREASED from 2.0 - focus more on hard examples
    label_smoothing: 0.1
    class_weights_scale: 2.0  # NEW: Scale class weights for minority classes

  # Class imbalance handling - ENHANCED
  class_balance:
    method: "both"  # CHANGED from "weighted_sampling" - use both techniques
    use_class_weights: true
    oversample_minority: true  # ENABLED: Oversample rare classes (Abuse, Fighting, etc.)
    minority_threshold: 1000  # NEW: Classes with <1000 samples will be oversampled
    oversample_ratio: 2.0  # NEW: Oversample minority classes 2x

  # Mixed precision training (FP16) - SPEED OPTIMIZATION
  mixed_precision: true # 2-3x faster training!

  # Model Compilation (PyTorch 2.0+) - TEMPORARILY DISABLED FOR STABILITY
  # Uses torch.compile() for 30-50% speedup
  compile_model:
    enabled: false  # DISABLED: torch.compile may interfere with gradient flow
    mode: "reduce-overhead" # Options: default, reduce-overhead, max-autotune
    # reduce-overhead: Best for single GPU (30% faster)
    # max-autotune: Best for multi-GPU (50% faster but longer compile)

  # Early stopping - INCREASED PATIENCE
  early_stopping:
    patience: 25  # INCREASED from 15 - allow more epochs for convergence
    min_delta: 0.0005  # REDUCED from 0.001 - more sensitive to improvements
    monitor: "val_f1_score"
    mode: "max"

  # Checkpointing - SAVE BEST MODEL EVERY EPOCH
  checkpoint:
    save_every_epoch: true  # NEW: Save checkpoint every epoch
    save_best_only: true  # NEW: Keep only the best model based on metric
    save_top_k: 5  # Keep top 5 best models (increased from 3)
    monitor: "val_f1_macro"  # FIXED: Use f1_macro to match actual metric key
    mode: "max"  # Higher F1 is better
    save_last: true  # Also save the last epoch checkpoint
    verbose: true  # Print when saving checkpoints

# Augmentation Configuration
augmentation:
  train:
    # Geometric transforms - ENHANCED diversity
    random_rotation: 20  # INCREASED from 15
    random_horizontal_flip: 0.5
    random_vertical_flip: 0.3  # INCREASED from 0.2
    random_affine:
      degrees: 15  # INCREASED from 10
      translate: [0.15, 0.15]  # INCREASED from [0.1, 0.1]
      scale: [0.85, 1.15]  # WIDER range from [0.9, 1.1]

    # Color transforms - ENHANCED for robustness
    color_jitter:
      brightness: 0.3  # INCREASED from 0.2
      contrast: 0.3  # INCREASED from 0.2
      saturation: 0.3  # INCREASED from 0.2
      hue: 0.15  # INCREASED from 0.1

    # Noise and blur - ENHANCED
    gaussian_blur:
      kernel_size: 5
      sigma: [0.1, 2.5]  # INCREASED from [0.1, 2.0]
      p: 0.4  # INCREASED from 0.3

    gaussian_noise:
      var_limit: [10, 70]  # INCREASED from [10, 50]
      p: 0.4  # INCREASED from 0.3

    # Adaptive augmentation for environment robustness - ENHANCED
    random_brightness_contrast: 0.5  # INCREASED from 0.4
    random_shadow: 0.4  # INCREASED from 0.3
    random_rain: 0.3  # INCREASED from 0.2
    
    # NEW: Additional augmentations for distribution robustness
    random_fog: 0.2  # NEW: Simulate foggy conditions

    # Advanced augmentation - Occlusion robustness
    # GridMask and Cutout for occlusion robustness
    coarse_dropout:
      enabled: true
      max_holes: 8
      max_height: 8
      max_width: 8
      p: 0.3

    # Random erasing for occlusion simulation
    random_erasing:
      enabled: true
      p: 0.3
      scale: [0.02, 0.33]
      ratio: [0.3, 3.3]

    # Normalization (ImageNet stats)
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

  val:
    # Only normalization for validation
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

# Validation Configuration
validation:
  split_ratio: 0.2 # 20% of training data for validation
  batch_size: 256

  # Metrics to track
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "auc_roc"
    - "confusion_matrix"

  # Validation frequency
  val_check_interval: 1.0 # Validate every epoch

# Inference Configuration
inference:
  # Anomaly detection thresholds
  confidence_threshold: 0.7 # Minimum confidence to report anomaly
  uncertainty_threshold: 0.3 # Maximum uncertainty allowed

  # Test-Time Augmentation (TTA) - NEW!
  # Improves robustness on unseen data
  tta:
    enabled: true # Enable TTA for inference
    augmentations: 5 # Number of augmented versions
    aggregation: "mean" # Options: mean, max, voting

  # Multi-camera settings
  multi_camera:
    enabled: true
    num_cameras: 3
    score_aggregation: "weighted_avg" # Options: max, avg, weighted_avg
    camera_weights: [0.4, 0.3, 0.3] # Importance of each camera
    consensus_threshold: 0.6 # Score to trigger alert

  # Alert categories and severity
  alert_categories:
    critical:
      classes:
        - "Shooting"
        - "Explosion"
        - "Arson"
        - "Robbery"
      threshold: 0.8
      notify:
        - "police"
        - "security"

    high:
      classes:
        - "Assault"
        - "Fighting"
        - "Burglary"
        - "Vandalism"
      threshold: 0.7
      notify:
        - "security"

    medium:
      classes:
        - "Abuse"
        - "Arrest"
        - "Stealing"
        - "Shoplifting"
      threshold: 0.6
      notify:
        - "security"

    low:
      classes:
        - "RoadAccidents"
      threshold: 0.5
      notify:
        - "monitoring"

  # Unknown anomaly handling
  unknown_anomaly:
    threshold: 0.5
    require_user_feedback: true

  # Performance optimization
  batch_inference: true
  max_batch_size: 64
  use_tensorrt: false # Enable for deployment

# Continual Learning Configuration
continual_learning:
  enabled: true

  # User feedback integration
  feedback:
    collect_low_confidence: true
    confidence_range: [0.3, 0.7]
    require_verification: true
    min_feedback_samples: 100

  # Retraining settings
  retrain:
    frequency: "weekly" # Options: daily, weekly, monthly
    min_new_samples: 500
    use_replay_buffer: true
    replay_ratio: 0.3

# Logging Configuration
logging:
  level: "INFO"
  save_dir: "outputs/logs"

  # TensorBoard
  tensorboard:
    enabled: true
    log_dir: "outputs/logs/tensorboard"

  # Weights & Biases
  wandb:
    enabled: true
    project: "anomaly-detection-ucf"
    entity: null # Your W&B username
    tags: ["surveillance", "multi-camera", "real-time"]

  # Logging frequency
  log_every_n_steps: 50
  log_gradients: false
  log_images: true
  log_images_interval: 500

# Hardware Configuration
hardware:
  device: "cuda" # Options: cuda, cpu
  gpu_ids: [0] # RTX 5090

  # CUDA optimization
  cudnn_benchmark: true
  cudnn_deterministic: false

  # Memory optimization
  empty_cache_interval: 100
  max_memory_allocated: "20GB"

# Experiment Tracking
experiment:
  name: "baseline_v1"
  notes: "Initial training with EfficientNet-B0 + LSTM"
  tags:
    - "baseline"
    - "efficientnet"
    - "focal_loss"
