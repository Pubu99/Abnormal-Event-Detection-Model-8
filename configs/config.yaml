# Main Configuration File for Anomaly Detection System
# All paths, hyperparameters, and settings

# Project Settings
project:
  name: "Multi-Camera-Anomaly-Detection"
  version: "1.0.0"
  description: "Real-time anomaly detection for surveillance systems"
  seed: 42

# Data Configuration
data:
  root_dir: "data/raw"
  train_dir: "data/raw/Train"
  test_dir: "data/raw/Test"
  processed_dir: "data/processed"

  # Dataset properties
  image_size: [64, 64]
  num_classes: 14
  classes:
    - "Abuse"
    - "Arrest"
    - "Arson"
    - "Assault"
    - "Burglary"
    - "Explosion"
    - "Fighting"
    - "NormalVideos"
    - "RoadAccidents"
    - "Robbery"
    - "Shooting"
    - "Shoplifting"
    - "Stealing"
    - "Vandalism"

  # Normal class (everything else is anomaly)
  normal_class_idx: 7 # NormalVideos

  # Data loading
  num_workers: 8
  pin_memory: true
  prefetch_factor: 2

# Model Configuration
model:
  name: "HybridAnomalyDetector"

  # Backbone
  backbone:
    type: "efficientnet_b0" # Fast and accurate
    pretrained: true
    freeze_backbone: false
    dropout: 0.3

  # Temporal modeling
  temporal:
    type: "lstm" # Options: lstm, gru, transformer
    hidden_dim: 256
    num_layers: 2
    bidirectional: true
    dropout: 0.3

  # Feature dimensions
  feature_dim: 512
  embedding_dim: 128

  # Anomaly detection head
  anomaly_head:
    type: "deep_svdd" # Deep Support Vector Data Description
    center_learning: true
    nu: 0.1 # Outlier fraction

# Training Configuration
training:
  # Basic settings
  epochs: 100
  batch_size: 128 # Optimized for RTX 5090
  gradient_accumulation_steps: 1 # Accumulate gradients over N steps (simulate larger batch)

  # Learning rate
  learning_rate: 0.001
  max_learning_rate: 0.01 # For OneCycleLR (10x base LR)

  lr_scheduler:
    type: "onecycle" # Options: onecycle, cosine_annealing, reduce_on_plateau
    # OneCycleLR (FAST TRAINING - 50% time savings!)
    T_max: 100
    eta_min: 0.00001
    warmup_epochs: 5
    pct_start: 0.3 # Percentage of cycle spent increasing LR
    div_factor: 25 # Initial LR = max_lr / div_factor
    final_div_factor: 10000 # Final LR = max_lr / final_div_factor

  # Optimizer
  optimizer:
    type: "adamw"
    weight_decay: 0.0001
    betas: [0.9, 0.999]

  # Sharpness-Aware Minimization (SAM) - NEW!
  # Seeks flat minima for better generalization on unseen data
  sam:
    enabled: true # Enable SAM for improved generalization
    rho: 0.05 # Neighborhood size (0.05 for AdamW, 0.2 for SGD)
    adaptive: false # Use ASAM (adaptive SAM)

  # Stochastic Weight Averaging (SWA) - NEW!
  # Averages weights over training for better generalization
  swa:
    enabled: true
    start_epoch: 75 # Start SWA at 75% of training
    lr: 0.00005 # SWA learning rate
    anneal_epochs: 10

  # Advanced Augmentation - NEW!
  # Mixup and CutMix for better generalization
  mixup_cutmix:
    enabled: true
    mixup_alpha: 0.2 # Mixup interpolation strength
    cutmix_alpha: 1.0 # CutMix interpolation strength
    prob: 0.5 # Probability of applying augmentation
    switch_prob: 0.5 # Probability of mixup vs cutmix

  # Loss function
  loss:
    type: "focal" # Better for class imbalance
    alpha: 0.25
    gamma: 2.0
    label_smoothing: 0.1

  # Class imbalance handling
  class_balance:
    method: "weighted_sampling" # Options: weighted_sampling, focal_loss, both
    use_class_weights: true
    oversample_minority: false

  # Mixed precision training (FP16) - SPEED OPTIMIZATION
  mixed_precision: true # 2-3x faster training!

  # Model Compilation (PyTorch 2.0+) - NEW SPEED OPTIMIZATION!
  # Uses torch.compile() for 30-50% speedup
  compile_model:
    enabled: true
    mode: "reduce-overhead" # Options: default, reduce-overhead, max-autotune
    # reduce-overhead: Best for single GPU (30% faster)
    # max-autotune: Best for multi-GPU (50% faster but longer compile)

  # Gradient clipping
  gradient_clip:
    enabled: true
    max_norm: 1.0

  # Early stopping
  early_stopping:
    patience: 15
    min_delta: 0.001
    monitor: "val_f1_score"
    mode: "max"

  # Checkpointing
  checkpoint:
    save_top_k: 3
    monitor: "val_f1_score"
    mode: "max"
    save_last: true

# Augmentation Configuration
augmentation:
  train:
    # Geometric transforms
    random_rotation: 15
    random_horizontal_flip: 0.5
    random_vertical_flip: 0.2
    random_affine:
      degrees: 10
      translate: [0.1, 0.1]
      scale: [0.9, 1.1]

    # Color transforms
    color_jitter:
      brightness: 0.2
      contrast: 0.2
      saturation: 0.2
      hue: 0.1

    # Noise and blur
    gaussian_blur:
      kernel_size: 5
      sigma: [0.1, 2.0]
      p: 0.3

    gaussian_noise:
      var_limit: [10, 50]
      p: 0.3

    # Adaptive augmentation for environment robustness
    random_brightness_contrast: 0.4
    random_shadow: 0.3
    random_rain: 0.2
    random_fog: 0.2

    # Advanced augmentation - NEW!
    # GridMask and Cutout for occlusion robustness
    coarse_dropout:
      enabled: true
      max_holes: 8
      max_height: 8
      max_width: 8
      p: 0.3

    # Random erasing for occlusion simulation
    random_erasing:
      enabled: true
      p: 0.3
      scale: [0.02, 0.33]
      ratio: [0.3, 3.3]

    # Normalization (ImageNet stats)
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

  val:
    # Only normalization for validation
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

# Validation Configuration
validation:
  split_ratio: 0.2 # 20% of training data for validation
  batch_size: 256

  # Metrics to track
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "auc_roc"
    - "confusion_matrix"

  # Validation frequency
  val_check_interval: 1.0 # Validate every epoch

# Inference Configuration
inference:
  # Anomaly detection thresholds
  confidence_threshold: 0.7 # Minimum confidence to report anomaly
  uncertainty_threshold: 0.3 # Maximum uncertainty allowed

  # Test-Time Augmentation (TTA) - NEW!
  # Improves robustness on unseen data
  tta:
    enabled: true # Enable TTA for inference
    augmentations: 5 # Number of augmented versions
    aggregation: "mean" # Options: mean, max, voting

  # Multi-camera settings
  multi_camera:
    enabled: true
    num_cameras: 3
    score_aggregation: "weighted_avg" # Options: max, avg, weighted_avg
    camera_weights: [0.4, 0.3, 0.3] # Importance of each camera
    consensus_threshold: 0.6 # Score to trigger alert

  # Alert categories and severity
  alert_categories:
    critical:
      classes:
        - "Shooting"
        - "Explosion"
        - "Arson"
        - "Robbery"
      threshold: 0.8
      notify:
        - "police"
        - "security"

    high:
      classes:
        - "Assault"
        - "Fighting"
        - "Burglary"
        - "Vandalism"
      threshold: 0.7
      notify:
        - "security"

    medium:
      classes:
        - "Abuse"
        - "Arrest"
        - "Stealing"
        - "Shoplifting"
      threshold: 0.6
      notify:
        - "security"

    low:
      classes:
        - "RoadAccidents"
      threshold: 0.5
      notify:
        - "monitoring"

  # Unknown anomaly handling
  unknown_anomaly:
    threshold: 0.5
    require_user_feedback: true

  # Performance optimization
  batch_inference: true
  max_batch_size: 64
  use_tensorrt: false # Enable for deployment

# Continual Learning Configuration
continual_learning:
  enabled: true

  # User feedback integration
  feedback:
    collect_low_confidence: true
    confidence_range: [0.3, 0.7]
    require_verification: true
    min_feedback_samples: 100

  # Retraining settings
  retrain:
    frequency: "weekly" # Options: daily, weekly, monthly
    min_new_samples: 500
    use_replay_buffer: true
    replay_ratio: 0.3

# Logging Configuration
logging:
  level: "INFO"
  save_dir: "outputs/logs"

  # TensorBoard
  tensorboard:
    enabled: true
    log_dir: "outputs/logs/tensorboard"

  # Weights & Biases
  wandb:
    enabled: true
    project: "anomaly-detection-ucf"
    entity: null # Your W&B username
    tags: ["surveillance", "multi-camera", "real-time"]

  # Logging frequency
  log_every_n_steps: 50
  log_gradients: false
  log_images: true
  log_images_interval: 500

# Hardware Configuration
hardware:
  device: "cuda" # Options: cuda, cpu
  gpu_ids: [0] # RTX 5090

  # CUDA optimization
  cudnn_benchmark: true
  cudnn_deterministic: false

  # Memory optimization
  empty_cache_interval: 100
  max_memory_allocated: "20GB"

# Experiment Tracking
experiment:
  name: "baseline_v1"
  notes: "Initial training with EfficientNet-B0 + LSTM"
  tags:
    - "baseline"
    - "efficientnet"
    - "focal_loss"
